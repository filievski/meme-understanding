{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gsdmm import MovieGroupProcess\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "from wordcloud import WordCloud\n",
    "import shutil\n",
    "stopwords = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>Text Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Milk Milk.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BREAKING NEWS: Russia releases photo of DONALD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0     1.jpg           0        0           0                0         0   \n",
       "1    10.jpg           1        0           0                0         1   \n",
       "2  1000.jpg           0        0           0                0         0   \n",
       "\n",
       "                                  Text Transcription  \n",
       "0                                      Milk Milk.zip  \n",
       "1  ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...  \n",
       "2  BREAKING NEWS: Russia releases photo of DONALD...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/extracted/TRAINING/training.csv\", delimiter='\\t')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    text = ' '.join([word for word in text.split() if len(word) >= 3])\n",
    "    text = ' '.join([word for word in text.split() if not re.match(r'\\b\\w+\\.(com|org|net)\\b', word)])\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = ' '.join([word for word in text.split() if len(word) >= 3])\n",
    "    return text\n",
    "\n",
    "texts = df['Text Transcription'].tolist()\n",
    "texts = list(map(preprocess, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 7401 clusters with 6 clusters populated\n",
      "In stage 1: transferred 4845 clusters with 6 clusters populated\n",
      "In stage 2: transferred 3906 clusters with 6 clusters populated\n",
      "In stage 3: transferred 3455 clusters with 6 clusters populated\n",
      "In stage 4: transferred 3172 clusters with 6 clusters populated\n",
      "In stage 5: transferred 2983 clusters with 6 clusters populated\n",
      "In stage 6: transferred 2745 clusters with 6 clusters populated\n",
      "In stage 7: transferred 2668 clusters with 6 clusters populated\n",
      "In stage 8: transferred 2583 clusters with 6 clusters populated\n",
      "In stage 9: transferred 2461 clusters with 6 clusters populated\n",
      "In stage 10: transferred 2488 clusters with 6 clusters populated\n",
      "In stage 11: transferred 2493 clusters with 6 clusters populated\n",
      "In stage 12: transferred 2389 clusters with 6 clusters populated\n",
      "In stage 13: transferred 2400 clusters with 6 clusters populated\n",
      "In stage 14: transferred 2410 clusters with 6 clusters populated\n"
     ]
    }
   ],
   "source": [
    "docs = [text.split() for text in texts]\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "vocab_length = len(dictionary)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "gsdmm = MovieGroupProcess(K=num_topics, alpha=0.1, beta=0.3, n_iters=15)\n",
    "\n",
    "y = gsdmm.fit(docs, vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gsdmm.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gsdmm, 'gsdmm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsdmm = joblib.load('gsdmm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [1137 2742 1955 1898 1356  912]\n",
      "Most important clusters (by number of docs inside): [1 2 3 4 0 5]\n"
     ]
    }
   ],
   "source": [
    "doc_count = np.array(gsdmm.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "\n",
    "top_index = doc_count.argsort()[-num_topics:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "\n",
    "# define function to get top words per topic\n",
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts = sorted(cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\"%(cluster, sort_dicts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'girlfriend': 335, 'wife': 330, 'get': 228, 'kitchen': 166, 'like': 166, 'house': 152, 'one': 135, 'woman': 130, 'mom': 130, 'hooker': 124, 'make': 120, 'prostitute': 114, 'know': 112, 'time': 108, 'girl': 107, 'you': 105, 'got': 105, 'want': 104, 'day': 102, 'home': 94}\n",
      "2: {'like': 354, 'girls': 233, 'girl': 175, 'women': 163, 'kitchen': 138, 'meme': 114, 'look': 111, 'one': 100, 'woman': 98, 'good': 86, 'know': 81, 'fat': 67, 'get': 66, 'girlfriend': 63, 'guy': 62, 'center': 62, 'see': 61, 'ass': 59, 'made': 58, 'new': 58}\n",
      "3: {'women': 672, 'men': 324, 'woman': 278, 'feminists': 157, 'man': 150, 'feminism': 145, 'feminist': 143, 'like': 138, 'want': 120, 'rights': 95, 'rape': 94, 'get': 91, 'equal': 88, 'people': 84, 'make': 81, 'womens': 75, 'female': 73, 'right': 65, 'girl': 63, 'think': 63}\n",
      "4: {'call': 154, 'house': 142, 'cooking': 79, 'people': 76, 'one': 70, 'cheat': 70, 'clean': 66, 'witch': 63, 'gold': 59, 'like': 56, 'get': 56, 'toilet': 53, 'paper': 48, 'new': 47, 'man': 47, 'wife': 47, 'work': 47, 'time': 46, 'game': 45, 'coronavirus': 43}\n",
      "0: {'women': 163, 'female': 124, 'like': 98, 'male': 95, 'man': 76, 'woman': 75, 'get': 69, 'feminist': 66, 'men': 64, 'one': 54, 'cant': 49, 'girl': 45, 'girls': 45, 'first': 41, 'know': 40, 'prostitute': 37, 'better': 37, 'cheat': 36, 'want': 36, 'reply': 35}\n",
      "5: {'people': 51, 'female': 51, 'make': 50, 'like': 49, 'gold': 49, 'women': 45, 'new': 44, 'woman': 38, 'trump': 37, 'coronavirus': 36, 'great': 36, 'made': 35, 'one': 34, 'man': 34, 'call': 34, 'wife': 34, 'black': 34, 'news': 33, 'never': 31, 'cheat': 31}\n"
     ]
    }
   ],
   "source": [
    "num_words = 20\n",
    "\n",
    "for topic_num in top_index:\n",
    "    topic_dict = dict(sorted(gsdmm.cluster_word_distribution[topic_num].items(), key=lambda k: k[1], reverse=True)[:num_words])\n",
    "    print(f\"{topic_num}: {topic_dict}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_font = \"milky_coffee/Milky Coffee.ttf\"\n",
    "\n",
    "\n",
    "output_directory = \"outputs_gsdmm\"\n",
    "shutil.rmtree(output_directory)\n",
    "os.mkdir(output_directory)\n",
    "\n",
    "\n",
    "\n",
    "cluster_word_distribution = gsdmm.cluster_word_distribution\n",
    "topic_num = 0\n",
    "num_words = 20\n",
    "\n",
    "for topic_num in top_index:\n",
    "\n",
    "    topic_dict = dict(sorted(cluster_word_distribution[topic_num].items(), key=lambda k: k[1], reverse=True)[:num_words])\n",
    "\n",
    "    # Generate a word cloud image\n",
    "    wordcloud = WordCloud(background_color='#fcf2ed', \n",
    "                                width=1800,\n",
    "                                height=700,\n",
    "                                font_path=path_to_font,\n",
    "                                colormap='flag').generate_from_frequencies(topic_dict)\n",
    "\n",
    "    wordcloud.to_file(os.path.join(output_directory, f\"topic_{topic_num}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0.40652958046338517)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdmm.choose_best_label(doc = ['feminist', 'cooking', 'kitchen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('meme-understanding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac3a4705714bedcbc0bf474a17d6c43d1f5f0469c7eabde18800deccbb1690fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
