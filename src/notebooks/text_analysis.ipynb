{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gsdmm import MovieGroupProcess\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "stopwords = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>Text Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Milk Milk.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BREAKING NEWS: Russia releases photo of DONALD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0     1.jpg           0        0           0                0         0   \n",
       "1    10.jpg           1        0           0                0         1   \n",
       "2  1000.jpg           0        0           0                0         0   \n",
       "\n",
       "                                  Text Transcription  \n",
       "0                                      Milk Milk.zip  \n",
       "1  ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...  \n",
       "2  BREAKING NEWS: Russia releases photo of DONALD...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/extracted/TRAINING/training.csv\", delimiter='\\t')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    text = ' '.join([word for word in text.split() if len(word) >= 3])\n",
    "    text = ' '.join([word for word in text.split() if not re.match(r'\\b\\w+\\.(com|org|net)\\b', word)])\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "texts = df['Text Transcription'].tolist()\n",
    "texts = list(map(preprocess, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 8495 clusters with 15 clusters populated\n",
      "In stage 1: transferred 5667 clusters with 15 clusters populated\n",
      "In stage 2: transferred 4579 clusters with 15 clusters populated\n",
      "In stage 3: transferred 4030 clusters with 15 clusters populated\n",
      "In stage 4: transferred 3752 clusters with 15 clusters populated\n",
      "In stage 5: transferred 3533 clusters with 15 clusters populated\n",
      "In stage 6: transferred 3393 clusters with 15 clusters populated\n",
      "In stage 7: transferred 3391 clusters with 15 clusters populated\n",
      "In stage 8: transferred 3282 clusters with 15 clusters populated\n",
      "In stage 9: transferred 3243 clusters with 15 clusters populated\n",
      "In stage 10: transferred 3064 clusters with 15 clusters populated\n",
      "In stage 11: transferred 3115 clusters with 15 clusters populated\n",
      "In stage 12: transferred 3111 clusters with 15 clusters populated\n",
      "In stage 13: transferred 3031 clusters with 15 clusters populated\n",
      "In stage 14: transferred 3008 clusters with 15 clusters populated\n"
     ]
    }
   ],
   "source": [
    "# cast tweets to numpy array\n",
    "docs = [text.split() for text in texts]\n",
    "\n",
    "# create dictionary of all words in all documents\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "\n",
    "# filter extreme cases out of dictionary\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "# create variable containing length of dictionary/vocab\n",
    "vocab_length = len(dictionary)\n",
    "\n",
    "# create BOW dictionary\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# initialize GSDMM\n",
    "gsdmm = MovieGroupProcess(K=15, alpha=0.1, beta=0.3, n_iters=15)\n",
    "\n",
    "# fit GSDMM model\n",
    "y = gsdmm.fit(docs, vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [ 596  527  313  375  806  732  945  605  443 1245  830 1017  761  560\n",
      "  245]\n",
      "Most important clusters (by number of docs inside): [ 9 11  6 10  4 12  5  7  0 13  1  8  3  2 14]\n"
     ]
    }
   ],
   "source": [
    "# print number of documents per topic\n",
    "doc_count = np.array(gsdmm.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "\n",
    "# Topics sorted by the number of document they are allocated to\n",
    "top_index = doc_count.argsort()[-15:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "\n",
    "# define function to get top words per topic\n",
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts = sorted(cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\"%(cluster, sort_dicts))\n",
    "\n",
    "# get top words in topics\n",
    "# top_words(gsdmm.cluster_word_distribution, top_index, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x152a762bb310>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "path_to_font = \"milky_coffee/Milky Coffee.ttf\"\n",
    "output_directory = \"outputs\"\n",
    "\n",
    "# Get topic word distributions from gsdmm model\n",
    "cluster_word_distribution = gsdmm.cluster_word_distribution\n",
    "topic_num = 0\n",
    "num_words = 20\n",
    "\n",
    "for topic_num in top_index:\n",
    "    # Select topic you want to output as dictionary (using topic_number)\n",
    "    topic_dict = dict(sorted(cluster_word_distribution[topic_num].items(), key=lambda k: k[1], reverse=True)[:num_words])\n",
    "\n",
    "    # Generate a word cloud image\n",
    "    wordcloud = WordCloud(background_color='#fcf2ed', \n",
    "                                width=1800,\n",
    "                                height=700,\n",
    "                                font_path=path_to_font,\n",
    "                                colormap='flag').generate_from_frequencies(topic_dict)\n",
    "\n",
    "    # Print to screen\n",
    "    # fig, ax = plt.subplots(figsize=[20,10])\n",
    "    # plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    # plt.axis(\"off\");\n",
    "\n",
    "    # Save to disk\n",
    "    wordcloud.to_file(os.path.join(output_directory, f\"topic_{topic_num}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('meme-understanding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac3a4705714bedcbc0bf474a17d6c43d1f5f0469c7eabde18800deccbb1690fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
