{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gsdmm import MovieGroupProcess\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import shutil\n",
    "stopwords = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>Text Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Milk Milk.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BREAKING NEWS: Russia releases photo of DONALD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0     1.jpg           0        0           0                0         0   \n",
       "1    10.jpg           1        0           0                0         1   \n",
       "2  1000.jpg           0        0           0                0         0   \n",
       "\n",
       "                                  Text Transcription  \n",
       "0                                      Milk Milk.zip  \n",
       "1  ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...  \n",
       "2  BREAKING NEWS: Russia releases photo of DONALD...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/extracted/TRAINING/training.csv\", delimiter='\\t')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    text = ' '.join([word for word in text.split() if len(word) >= 3])\n",
    "    text = ' '.join([word for word in text.split() if not re.match(r'\\b\\w+\\.(com|org|net)\\b', word)])\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "texts = df['Text Transcription'].tolist()\n",
    "texts = list(map(preprocess, texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 7378 clusters with 6 clusters populated\n",
      "In stage 1: transferred 4798 clusters with 6 clusters populated\n",
      "In stage 2: transferred 3869 clusters with 6 clusters populated\n",
      "In stage 3: transferred 3475 clusters with 6 clusters populated\n",
      "In stage 4: transferred 3150 clusters with 6 clusters populated\n",
      "In stage 5: transferred 3072 clusters with 6 clusters populated\n",
      "In stage 6: transferred 2829 clusters with 6 clusters populated\n",
      "In stage 7: transferred 2727 clusters with 6 clusters populated\n",
      "In stage 8: transferred 2695 clusters with 6 clusters populated\n",
      "In stage 9: transferred 2595 clusters with 6 clusters populated\n",
      "In stage 10: transferred 2482 clusters with 6 clusters populated\n",
      "In stage 11: transferred 2466 clusters with 6 clusters populated\n",
      "In stage 12: transferred 2461 clusters with 6 clusters populated\n",
      "In stage 13: transferred 2451 clusters with 6 clusters populated\n",
      "In stage 14: transferred 2353 clusters with 6 clusters populated\n"
     ]
    }
   ],
   "source": [
    "docs = [text.split() for text in texts]\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "vocab_length = len(dictionary)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "gsdmm = MovieGroupProcess(K=num_topics, alpha=0.1, beta=0.3, n_iters=15)\n",
    "\n",
    "y = gsdmm.fit(docs, vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [1547 2674 1726 1182 2211  660]\n",
      "Most important clusters (by number of docs inside): [1 4 2 0 3 5]\n"
     ]
    }
   ],
   "source": [
    "doc_count = np.array(gsdmm.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "\n",
    "top_index = doc_count.argsort()[-num_topics:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "\n",
    "# define function to get top words per topic\n",
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts = sorted(cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\"%(cluster, sort_dicts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_font = \"milky_coffee/Milky Coffee.ttf\"\n",
    "\n",
    "\n",
    "output_directory = \"outputs\"\n",
    "shutil.rmtree(output_directory)\n",
    "os.mkdir(output_directory)\n",
    "\n",
    "\n",
    "\n",
    "cluster_word_distribution = gsdmm.cluster_word_distribution\n",
    "topic_num = 0\n",
    "num_words = 20\n",
    "\n",
    "for topic_num in top_index:\n",
    "\n",
    "    topic_dict = dict(sorted(cluster_word_distribution[topic_num].items(), key=lambda k: k[1], reverse=True)[:num_words])\n",
    "\n",
    "    # Generate a word cloud image\n",
    "    wordcloud = WordCloud(background_color='#fcf2ed', \n",
    "                                width=1800,\n",
    "                                height=700,\n",
    "                                font_path=path_to_font,\n",
    "                                colormap='flag').generate_from_frequencies(topic_dict)\n",
    "\n",
    "    wordcloud.to_file(os.path.join(output_directory, f\"topic_{topic_num}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0.40652958046338517)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdmm.choose_best_label(doc = ['feminist', 'cooking', 'kitchen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('meme-understanding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac3a4705714bedcbc0bf474a17d6c43d1f5f0469c7eabde18800deccbb1690fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
